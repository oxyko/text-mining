{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Naïve Bayes text classifier for sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of a simple classifier using natural language processing with NLTK library. It uses a simple Naïve Bayes classifier (which is part of nltk) and pickles resulting classifier for future use.\n",
    "\n",
    "Info on NLTK: http://www.nltk.org/book/\n",
    "\n",
    "The approach we take here is quite simple. \n",
    "1. We have a labeled dataset of movie reviews (positive and negative). \n",
    "2. We combine all the reviews and tokenize them into words. \n",
    "3. Then we pick the most frequently used words. Note that we do not stem/lemmatize, remove stopwords or take grammar into consideration. This is because we use a Naïve Bayes algorithm to determine which of the most common words are founds mostly in positive or negative reviews. This step will take care of the grammar and irrelevant words (like \"the\", \"to\", punctuation, etc.).\n",
    "4. Use Naïve Bayes to classify which of the commonly used words are more common in positive or negative reviews. We use a training set (subset of reviews) for this.\n",
    "5. Use the 2 sets of positive and negative words to classify the rest of the documents. We use a testing set of reviews for this.\n",
    "6. Evaluate the performance of the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "from nltk.corpus import movie_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create corpus \n",
    "This will be the list of all reviews with their category (positive or negative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg', 'neg', 'neg', 'neg', 'neg', 'neg', 'neg', 'neg', 'neg', 'neg']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "            for category in movie_reviews.categories()\n",
    "            for fileid in movie_reviews.fileids(category)]\n",
    "'''\n",
    "## Same as:\n",
    "documents = []\n",
    "for category in movie_reviews.categories():\n",
    "    for fileid in movie_reviews.fileids(category):\n",
    "        documents.append(list(movie_reviews.words(fileid), category)\n",
    "'''\n",
    "[d[1] for d in documents[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## No need to re-shuffle the documents, we will re-shuffle the feature sets further on.\n",
    "#random.shuffle(documents)\n",
    "#[d[1] for d in documents[:10]]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select most common words in all reviews (positive and negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = []\n",
    "for w in movie_reviews.words():\n",
    "    all_words.append(w.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert all_words from a list to a frequency distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 77717),\n",
       " ('the', 76529),\n",
       " ('.', 65876),\n",
       " ('a', 38106),\n",
       " ('and', 35576),\n",
       " ('of', 34123),\n",
       " ('to', 31937),\n",
       " (\"'\", 30585),\n",
       " ('is', 25195),\n",
       " ('in', 21822),\n",
       " ('s', 18513),\n",
       " ('\"', 17612),\n",
       " ('it', 16107),\n",
       " ('that', 15924),\n",
       " ('-', 15595)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words = nltk.FreqDist(all_words)\n",
    "all_words.most_common(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## See what we've got\n",
    "all_words.elements  ## This is sorted by frequency list of elements with frequencies\n",
    "all_words.keys()  ## This list is not sorted\n",
    "all_words[\"smart\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select only top commonly used words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[',', 'the', '.', 'a', 'and', 'of', 'to', \"'\", 'is', 'in', 's', '\"', 'it', 'that', '-', ')', '(', 'as', 'with', 'for', 'his', 'this', 'film', 'i', 'he', 'but', 'on', 'are', 't', 'by']\n"
     ]
    }
   ],
   "source": [
    "word_features = [wordFreq[0] for wordFreq in all_words.most_common(3000)]\n",
    "#word_features = list(all_words.keys())[:3000]  # takes random words, not the most common\n",
    "\n",
    "print([wf for wf in word_features[:30]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all the words in all the reviews, find if they are in the commonly used words set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit -r1 -n1\n",
    "\n",
    "def find_features(document):\n",
    "    words = set(document)  ## pick only unique words in the review\n",
    "    features = {}\n",
    "    for w in words:\n",
    "        features[w] = (w in word_features)\n",
    "    return features\n",
    "\n",
    "#find_features(movie_reviews.words('pos/cv980_10953.txt'))\n",
    "#find_features(movie_reviews.words('neg/cv974_24303.txt'))\n",
    "\n",
    "feature_sets = [(find_features(review_words),category) for review_words, category in documents]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature_sets is a list of (__dict__, __str__) elements, where \n",
    "- __dict__ is a dictionary of unique words in a review with True/False values for whether this word is in commonly used set\n",
    "- __str__ is a pos/neg category of the review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'a': True,\n",
       "  'that': True,\n",
       "  'not': True,\n",
       "  '10': True,\n",
       "  'sagemiller': False,\n",
       "  'girlfriend': True,\n",
       "  'coming': True,\n",
       "  'music': True,\n",
       "  'touches': True,\n",
       "  'stick': True,\n",
       "  'looooot': False,\n",
       "  'taken': True,\n",
       "  'unravel': False,\n",
       "  '&': True,\n",
       "  'and': True,\n",
       "  'want': True,\n",
       "  'sure': True,\n",
       "  'starts': True,\n",
       "  'down': True,\n",
       "  'entire': True,\n",
       "  'drive': True,\n",
       "  'good': True,\n",
       "  'salvation': False,\n",
       "  'need': True,\n",
       "  've': True,\n",
       "  'somewhere': True,\n",
       "  'attempt': True,\n",
       "  'kudos': False,\n",
       "  'or': True,\n",
       "  'critique': True,\n",
       "  'is': True,\n",
       "  'what': True,\n",
       "  '8': True,\n",
       "  'production': True,\n",
       "  'craziness': False,\n",
       "  'plain': True,\n",
       "  'doesn': True,\n",
       "  ')': True,\n",
       "  'in': True,\n",
       "  'us': True,\n",
       "  'concept': True,\n",
       "  'character': True,\n",
       "  'crow': True,\n",
       "  'echoes': False,\n",
       "  'unraveling': False,\n",
       "  'see': True,\n",
       "  'more': True,\n",
       "  'apparitions': False,\n",
       "  'her': True,\n",
       "  'sense': True,\n",
       "  'couples': False,\n",
       "  'holds': True,\n",
       "  'always': True,\n",
       "  'know': True,\n",
       "  'drink': False,\n",
       "  'new': True,\n",
       "  'mean': True,\n",
       "  '20': True,\n",
       "  'despite': True,\n",
       "  'here': True,\n",
       "  'he': True,\n",
       "  'me': True,\n",
       "  'pretty': True,\n",
       "  'lost': True,\n",
       "  'stir': False,\n",
       "  'bottom': True,\n",
       "  'neat': False,\n",
       "  'actually': True,\n",
       "  'chase': True,\n",
       "  'kind': True,\n",
       "  'edge': True,\n",
       "  'sitting': True,\n",
       "  'neighborhood': False,\n",
       "  'hide': False,\n",
       "  'idea': True,\n",
       "  'meantime': False,\n",
       "  'jumbled': False,\n",
       "  'package': False,\n",
       "  'terribly': True,\n",
       "  'get': True,\n",
       "  'insight': True,\n",
       "  'feeling': True,\n",
       "  ',': True,\n",
       "  's': True,\n",
       "  'folks': True,\n",
       "  'fuck': False,\n",
       "  'simply': True,\n",
       "  'accident': True,\n",
       "  'beauty': True,\n",
       "  'joblo': False,\n",
       "  'on': True,\n",
       "  'harder': False,\n",
       "  'street': True,\n",
       "  ':': True,\n",
       "  'such': True,\n",
       "  'further': True,\n",
       "  'since': True,\n",
       "  'for': True,\n",
       "  'with': True,\n",
       "  'dead': True,\n",
       "  '2': True,\n",
       "  'shelves': False,\n",
       "  '/': True,\n",
       "  'wrapped': False,\n",
       "  'because': True,\n",
       "  'scenes': True,\n",
       "  'break': True,\n",
       "  'now': True,\n",
       "  'also': True,\n",
       "  'teen': True,\n",
       "  'little': True,\n",
       "  'entertaining': True,\n",
       "  'world': True,\n",
       "  'applaud': False,\n",
       "  'memento': False,\n",
       "  'different': True,\n",
       "  'given': True,\n",
       "  'every': True,\n",
       "  'like': True,\n",
       "  'sad': True,\n",
       "  'dreams': True,\n",
       "  'decent': True,\n",
       "  'assuming': False,\n",
       "  '7': True,\n",
       "  'redundant': False,\n",
       "  'actors': True,\n",
       "  'people': True,\n",
       "  'the': True,\n",
       "  'came': True,\n",
       "  'disappearances': False,\n",
       "  'before': True,\n",
       "  'sorta': False,\n",
       "  'showing': True,\n",
       "  'church': True,\n",
       "  'have': True,\n",
       "  'i': True,\n",
       "  'find': True,\n",
       "  '!': True,\n",
       "  'while': True,\n",
       "  'might': True,\n",
       "  'ways': True,\n",
       "  'horror': True,\n",
       "  'audience': True,\n",
       "  'about': True,\n",
       "  'two': True,\n",
       "  'really': True,\n",
       "  'movies': True,\n",
       "  'back': True,\n",
       "  'generally': True,\n",
       "  'nightmare': True,\n",
       "  'look': True,\n",
       "  'an': True,\n",
       "  'my': True,\n",
       "  '9': True,\n",
       "  'secret': True,\n",
       "  'explained': True,\n",
       "  'blair': True,\n",
       "  'shows': True,\n",
       "  'flicks': True,\n",
       "  'head': True,\n",
       "  'so': True,\n",
       "  'away': True,\n",
       "  'packaged': False,\n",
       "  'nightmares': False,\n",
       "  'five': True,\n",
       "  'continues': True,\n",
       "  'years': True,\n",
       "  'entertain': True,\n",
       "  'does': True,\n",
       "  'fed': False,\n",
       "  'tons': False,\n",
       "  'hot': True,\n",
       "  'life': True,\n",
       "  'giving': True,\n",
       "  'presents': True,\n",
       "  'melissa': False,\n",
       "  'excites': False,\n",
       "  'okay': True,\n",
       "  'suits': True,\n",
       "  'start': True,\n",
       "  'strange': True,\n",
       "  'to': True,\n",
       "  'write': True,\n",
       "  'make': True,\n",
       "  'up': True,\n",
       "  'even': True,\n",
       "  'would': True,\n",
       "  'be': True,\n",
       "  'offering': False,\n",
       "  'how': True,\n",
       "  'overall': True,\n",
       "  'point': True,\n",
       "  'visions': False,\n",
       "  'cool': True,\n",
       "  'going': True,\n",
       "  'mold': False,\n",
       "  'party': True,\n",
       "  'fantasy': True,\n",
       "  'films': True,\n",
       "  'chasing': False,\n",
       "  'it': True,\n",
       "  'weird': True,\n",
       "  'his': True,\n",
       "  'main': True,\n",
       "  'took': True,\n",
       "  'most': True,\n",
       "  'thrilling': True,\n",
       "  'director': True,\n",
       "  'guess': True,\n",
       "  'feels': True,\n",
       "  'happen': True,\n",
       "  'did': True,\n",
       "  'when': True,\n",
       "  'runtime': False,\n",
       "  'problem': True,\n",
       "  'into': True,\n",
       "  'all': True,\n",
       "  'seems': True,\n",
       "  'still': True,\n",
       "  'we': True,\n",
       "  'its': True,\n",
       "  'exact': True,\n",
       "  'of': True,\n",
       "  'are': True,\n",
       "  'apparently': True,\n",
       "  'bentley': False,\n",
       "  'downshifts': False,\n",
       "  'witch': True,\n",
       "  'explanation': True,\n",
       "  '4': True,\n",
       "  'but': True,\n",
       "  'arrow': False,\n",
       "  'film': True,\n",
       "  'again': True,\n",
       "  'ago': True,\n",
       "  'chopped': False,\n",
       "  'slasher': True,\n",
       "  'elm': False,\n",
       "  'although': True,\n",
       "  'dies': True,\n",
       "  'generation': True,\n",
       "  'you': True,\n",
       "  'strangeness': False,\n",
       "  'kids': True,\n",
       "  'lazy': False,\n",
       "  'snag': False,\n",
       "  'mind': True,\n",
       "  't': True,\n",
       "  'got': True,\n",
       "  'others': True,\n",
       "  'types': True,\n",
       "  'minutes': True,\n",
       "  '\"': True,\n",
       "  'very': True,\n",
       "  'genre': True,\n",
       "  'just': True,\n",
       "  'don': True,\n",
       "  'final': True,\n",
       "  'review': True,\n",
       "  'characters': True,\n",
       "  'line': True,\n",
       "  'who': True,\n",
       "  'mess': True,\n",
       "  'studio': True,\n",
       "  'big': True,\n",
       "  'video': True,\n",
       "  'executed': True,\n",
       "  'they': True,\n",
       "  'plot': True,\n",
       "  'playing': True,\n",
       "  'didn': True,\n",
       "  '-': True,\n",
       "  'off': True,\n",
       "  'seemed': True,\n",
       "  'flick': True,\n",
       "  'these': True,\n",
       "  'biggest': True,\n",
       "  'as': True,\n",
       "  'guys': True,\n",
       "  'engaging': True,\n",
       "  'completely': True,\n",
       "  'should': True,\n",
       "  'seem': True,\n",
       "  'american': True,\n",
       "  'correctly': False,\n",
       "  'clue': True,\n",
       "  'whatever': True,\n",
       "  '?': True,\n",
       "  'do': True,\n",
       "  'enter': True,\n",
       "  'someone': True,\n",
       "  'things': True,\n",
       "  'turning': True,\n",
       "  'part': True,\n",
       "  'your': True,\n",
       "  'ever': True,\n",
       "  \"'\": True,\n",
       "  'bad': True,\n",
       "  'well': True,\n",
       "  'watch': True,\n",
       "  'has': True,\n",
       "  'personally': True,\n",
       "  'problems': True,\n",
       "  'there': True,\n",
       "  'out': True,\n",
       "  'no': True,\n",
       "  'decided': True,\n",
       "  'making': True,\n",
       "  'after': True,\n",
       "  'makes': True,\n",
       "  'normal': True,\n",
       "  'running': True,\n",
       "  'bit': True,\n",
       "  'same': True,\n",
       "  '.': True,\n",
       "  'password': False,\n",
       "  'by': True,\n",
       "  'confusing': True,\n",
       "  'go': True,\n",
       "  'skip': True,\n",
       "  'from': True,\n",
       "  'own': True,\n",
       "  'throughout': True,\n",
       "  'where': True,\n",
       "  'both': True,\n",
       "  'member': True,\n",
       "  'understanding': True,\n",
       "  'too': True,\n",
       "  'way': True,\n",
       "  'this': True,\n",
       "  'themselves': True,\n",
       "  'dig': False,\n",
       "  'only': True,\n",
       "  'then': True,\n",
       "  'him': True,\n",
       "  'trying': True,\n",
       "  'deal': True,\n",
       "  'rarely': True,\n",
       "  'which': True,\n",
       "  'ending': True,\n",
       "  'oh': True,\n",
       "  'until': True,\n",
       "  '3': True,\n",
       "  'over': True,\n",
       "  'been': True,\n",
       "  'highway': False,\n",
       "  'wes': True,\n",
       "  'figured': False,\n",
       "  'half': True,\n",
       "  'obviously': True,\n",
       "  'movie': True,\n",
       "  'one': True,\n",
       "  'give': True,\n",
       "  '(': True},\n",
       " 'neg')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_sets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(feature_sets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Naïve Bayes to classify the text.\n",
    "\n",
    "NB is a popular baseline method for text categorization. It classifies data into 2 (and only 2) categories (true/false) and uses word frequencies as features.\n",
    "\n",
    "In a nutshell: __posterior = prior occurences * likelyhood / evidence__\n",
    "\n",
    "Advantages: \n",
    "* needs a small set of training data to estimate parameters for classification\n",
    "* scalable (linear)\n",
    "* with proper pre-processing can be comparable with more complicated methods\n",
    "\n",
    "Disadvantages:\n",
    "* strong (naïve) independence assumptions between features\n",
    "* outperformed by other approaches (boosted trees, random forrests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Re-shuffle feature sets and select training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg', 'pos', 'neg', 'neg', 'pos', 'pos', 'neg', 'pos', 'pos', 'neg']"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[d[1] for d in feature_sets[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pos', 'pos', 'neg', 'neg', 'neg', 'neg', 'pos', 'neg', 'pos', 'neg']"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.shuffle(feature_sets)\n",
    "\n",
    "[d[1] for d in feature_sets[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = feature_sets[:1900]\n",
    "testing_set = feature_sets[1900:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier accuracy: 0.71\n",
      "1.86 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r1 -n1\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
    "classifier_accuracy = nltk.classify.accuracy(classifier, testing_set)\n",
    "print(\"Classifier accuracy: {}\".format(classifier_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                  regard = False             pos : neg    =     11.9 : 1.0\n",
      "                    slip = False             pos : neg    =     11.9 : 1.0\n",
      "                  avoids = False             pos : neg    =     11.9 : 1.0\n",
      "             fascination = False             pos : neg    =     11.2 : 1.0\n",
      "                    3000 = False             neg : pos    =     10.8 : 1.0\n",
      "             outstanding = True              pos : neg    =     10.6 : 1.0\n",
      "                  hatred = False             pos : neg    =     10.5 : 1.0\n",
      "                seamless = False             pos : neg    =     10.5 : 1.0\n",
      "              astounding = False             pos : neg    =     10.5 : 1.0\n",
      "                   sucks = False             neg : pos    =     10.4 : 1.0\n",
      "                  hudson = False             neg : pos    =     10.2 : 1.0\n",
      "               insulting = False             neg : pos    =     10.0 : 1.0\n",
      "               ludicrous = False             neg : pos    =     10.0 : 1.0\n",
      "               addresses = False             pos : neg    =      9.8 : 1.0\n",
      "              incoherent = False             neg : pos    =      9.5 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save a trained classifier for future use using Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Skip this step if you are running for the 2nd > time to see the difference between new and pickled classifier\n",
    "import pickle\n",
    "\n",
    "with open(\"nb_txt_classifier.pickle\", 'wb') as pickle_file:\n",
    "    pickle.dump(classifier, pickle_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 32616\r\n",
      "-rw-r--r--  1 korolo  10513     1069 10 Jul 16:51 LICENSE\r\n",
      "-rw-r--r--  1 korolo  10513      108 10 Jul 16:51 README.md\r\n",
      "-rw-r--r--  1 korolo  10513  7868888 13 Jul 15:48 nb_txt_classifier.pickle\r\n",
      "-rw-r--r--  1 korolo  10513   914288 13 Jul 10:32 nltk.ipynb\r\n",
      "-rw-r--r--  1 korolo  10513    25219 13 Jul 15:48 txt_classifier.ipynb\r\n",
      "-rw-r--r--  1 korolo  10513  7868888 13 Jul 15:47 txt_classifier.pickle\r\n"
     ]
    }
   ],
   "source": [
    "## See if the pickle file was saved to disk:\n",
    "%ll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-using a pickled classifier\n",
    "\n",
    "Note that in this particular example, newly reshuffled testing set will likely contain the reviews, which were used in the pickled classifier training set. So the performance of the pickled classifier here will almost always be better than the fresh classifier above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"nb_txt_classifier.pickle\", 'rb') as pickled_classifier:\n",
    "    classifier_p = pickle.load(pickled_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickled Classifier accuracy: 0.95\n",
      "166 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r1 -n1\n",
    "classifier_accuracy = nltk.classify.accuracy(classifier, testing_set)\n",
    "print(\"Pickled Classifier accuracy: {}\".format(classifier_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
